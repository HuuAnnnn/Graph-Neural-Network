{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric import datasets\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cora = datasets.Planetoid(root=\".\", name=\"Cora\", transform=NormalizeFeatures())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number sample: 2708\n",
      "Number of features: 1433\n",
      "Number of classes: 7\n",
      "Number of nodes: 2708\n",
      "Number of training nodes: 140\n",
      "Is undirected? True\n"
     ]
    }
   ],
   "source": [
    "dataset = cora[0]\n",
    "print(f\"Number sample: {len(cora.x)}\")\n",
    "print(f\"Number of features: {cora.num_features}\")\n",
    "print(f\"Number of classes: {cora.num_classes}\")\n",
    "print(f\"Number of nodes: {dataset.num_nodes}\")\n",
    "print(f\"Number of training nodes: {dataset.train_mask.sum()}\")\n",
    "print(f\"Is undirected? {dataset.is_undirected()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = dataset.edge_index.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dataset.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G.add_edges_from(edges.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = {}\n",
    "colors = [\"blue\", \"green\", \"red\", \"yellow\", \"black\", \"orange\", \"magma\"]\n",
    "c_map = {i : colors[i] for i in range(7)}\n",
    "nodes_color = []\n",
    "nodes = []\n",
    "for node in G:\n",
    "  nodes.append(node)\n",
    "  nodes_color.append(c_map[labels[node].item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       6\n",
       "1       6\n",
       "2       6\n",
       "3       6\n",
       "4       0\n",
       "       ..\n",
       "2703    5\n",
       "2704    0\n",
       "2705    0\n",
       "2706    0\n",
       "2707    0\n",
       "Length: 2708, dtype: int8"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carac = pd.DataFrame({\"node\" : nodes, \"colors\" : nodes_color})\n",
    "\n",
    "carac['colors']=pd.Categorical(carac['colors'])\n",
    "carac['colors'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./cora_graph.png\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"./cora_graph.png\"):\n",
    "  plt.figure(figsize=(100, 50))\n",
    "  pos = nx.kamada_kawai_layout(G)\n",
    "  nx.draw(G, pos, node_color=carac['colors'].cat.codes, with_labels=True)\n",
    "  plt.savefig(\"cora_graph.png\", dpi=150, bbox_inches=\"tight\")\n",
    "  plt.show()\n",
    "else:\n",
    "  print(\"./cora_graph.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_RATIO = 0.8\n",
    "TRAIN_LIMIT = int(TRAIN_RATIO * len(cora.x))\n",
    "TEST_LIMIT = int((1 - TRAIN_RATIO) * len(cora.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size, output_size) -> None:\n",
    "    super(GNN, self).__init__()\n",
    "    self.conv1 = GCNConv(input_size, hidden_size)\n",
    "    self.conv2 = GCNConv(hidden_size, hidden_size)\n",
    "    self.conv3 = GCNConv(hidden_size, hidden_size)\n",
    "    self.out = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "  def forward(self, X, edges_index):\n",
    "    out = X\n",
    "    out = self.conv1(out, edges_index)\n",
    "    out = out.relu()\n",
    "    out = F.dropout(out, p=.5, training=self.training)\n",
    "    \n",
    "    out = self.conv2(out, edges_index)\n",
    "    out = out.relu()\n",
    "    out = F.dropout(out, p=.5, training=self.training)\n",
    "    \n",
    "    out = self.conv3(out, edges_index)\n",
    "    out = out.relu()\n",
    "    out = F.dropout(out, p=.5, training=self.training)\n",
    "    \n",
    "    out = self.out(out)\n",
    "    out = F.softmax(out, dim=1)\n",
    "    return out\n",
    "  \n",
    "  \n",
    "  def get_parameters(self):\n",
    "    return sum(parameter.numel() for parameter in self.parameters())\n",
    "  \n",
    "  def __str__(self):\n",
    "    return super(GNN, self).__str__() + \\\n",
    "          f\"\\nNumber of parameters: {self.get_parameters():,}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 256\n",
    "model = GNN(cora.num_features, LATENT_DIM, cora.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN(\n",
      "  (conv1): GCNConv(1433, 256)\n",
      "  (conv2): GCNConv(256, 256)\n",
      "  (conv3): GCNConv(256, 256)\n",
      "  (out): Linear(in_features=256, out_features=7, bias=True)\n",
      ")\n",
      "Number of parameters: 500,487\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1000\n",
    "VERBOSE = 10\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "dataset = dataset.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 1.9459260702133179\n",
      "Epoch 2 | Loss: 1.9458328485488892\n",
      "Epoch 3 | Loss: 1.9457166194915771\n",
      "Epoch 4 | Loss: 1.945623755455017\n",
      "Epoch 5 | Loss: 1.9455037117004395\n",
      "Epoch 6 | Loss: 1.945251703262329\n",
      "Epoch 7 | Loss: 1.9450417757034302\n",
      "Epoch 8 | Loss: 1.9447963237762451\n",
      "Epoch 9 | Loss: 1.944431185722351\n",
      "Epoch 10 | Loss: 1.944149136543274\n",
      "Epoch 11 | Loss: 1.9434877634048462\n",
      "Epoch 12 | Loss: 1.942784070968628\n",
      "Epoch 13 | Loss: 1.9422409534454346\n",
      "Epoch 14 | Loss: 1.9415146112442017\n",
      "Epoch 15 | Loss: 1.939968228340149\n",
      "Epoch 16 | Loss: 1.9394941329956055\n",
      "Epoch 17 | Loss: 1.9378646612167358\n",
      "Epoch 18 | Loss: 1.936341643333435\n",
      "Epoch 19 | Loss: 1.9340912103652954\n",
      "Epoch 20 | Loss: 1.9316822290420532\n",
      "Epoch 21 | Loss: 1.929567575454712\n",
      "Epoch 22 | Loss: 1.9261879920959473\n",
      "Epoch 23 | Loss: 1.9223111867904663\n",
      "Epoch 24 | Loss: 1.9186174869537354\n",
      "Epoch 25 | Loss: 1.9142643213272095\n",
      "Epoch 26 | Loss: 1.9068958759307861\n",
      "Epoch 27 | Loss: 1.8996564149856567\n",
      "Epoch 28 | Loss: 1.890442967414856\n",
      "Epoch 29 | Loss: 1.8847508430480957\n",
      "Epoch 30 | Loss: 1.8710052967071533\n",
      "Epoch 31 | Loss: 1.8639776706695557\n",
      "Epoch 32 | Loss: 1.8451725244522095\n",
      "Epoch 33 | Loss: 1.8237749338150024\n",
      "Epoch 34 | Loss: 1.8119994401931763\n",
      "Epoch 35 | Loss: 1.7982641458511353\n",
      "Epoch 36 | Loss: 1.7808302640914917\n",
      "Epoch 37 | Loss: 1.7647403478622437\n",
      "Epoch 38 | Loss: 1.7473124265670776\n",
      "Epoch 39 | Loss: 1.7224993705749512\n",
      "Epoch 40 | Loss: 1.7031060457229614\n",
      "Epoch 41 | Loss: 1.6880842447280884\n",
      "Epoch 42 | Loss: 1.6657116413116455\n",
      "Epoch 43 | Loss: 1.6472525596618652\n",
      "Epoch 44 | Loss: 1.6133308410644531\n",
      "Epoch 45 | Loss: 1.6041730642318726\n",
      "Epoch 46 | Loss: 1.581319808959961\n",
      "Epoch 47 | Loss: 1.5464287996292114\n",
      "Epoch 48 | Loss: 1.5313611030578613\n",
      "Epoch 49 | Loss: 1.5167471170425415\n",
      "Epoch 50 | Loss: 1.4833065271377563\n",
      "Epoch 51 | Loss: 1.4574627876281738\n",
      "Epoch 52 | Loss: 1.4460740089416504\n",
      "Epoch 53 | Loss: 1.4225434064865112\n",
      "Epoch 54 | Loss: 1.412967562675476\n",
      "Epoch 55 | Loss: 1.3825938701629639\n",
      "Epoch 56 | Loss: 1.3696630001068115\n",
      "Epoch 57 | Loss: 1.3454363346099854\n",
      "Epoch 58 | Loss: 1.3293806314468384\n",
      "Epoch 59 | Loss: 1.3264596462249756\n",
      "Epoch 60 | Loss: 1.2947160005569458\n",
      "Epoch 61 | Loss: 1.309270977973938\n",
      "Epoch 62 | Loss: 1.2855019569396973\n",
      "Epoch 63 | Loss: 1.2948122024536133\n",
      "Epoch 64 | Loss: 1.2786154747009277\n",
      "Epoch 65 | Loss: 1.2739839553833008\n",
      "Epoch 66 | Loss: 1.2579926252365112\n",
      "Epoch 67 | Loss: 1.25471031665802\n",
      "Epoch 68 | Loss: 1.2429929971694946\n",
      "Epoch 69 | Loss: 1.2429661750793457\n",
      "Epoch 70 | Loss: 1.2420545816421509\n",
      "Epoch 71 | Loss: 1.231188178062439\n",
      "Epoch 72 | Loss: 1.2261217832565308\n",
      "Epoch 73 | Loss: 1.2288718223571777\n",
      "Epoch 74 | Loss: 1.212989330291748\n",
      "Epoch 75 | Loss: 1.219254970550537\n",
      "Epoch 76 | Loss: 1.2264204025268555\n",
      "Epoch 77 | Loss: 1.213171362876892\n",
      "Epoch 78 | Loss: 1.2110909223556519\n",
      "Epoch 79 | Loss: 1.2072283029556274\n",
      "Epoch 80 | Loss: 1.1956425905227661\n",
      "Epoch 81 | Loss: 1.200010061264038\n",
      "Epoch 82 | Loss: 1.1950987577438354\n",
      "Epoch 83 | Loss: 1.191789984703064\n",
      "Epoch 84 | Loss: 1.201155424118042\n",
      "Epoch 85 | Loss: 1.1983448266983032\n",
      "Epoch 86 | Loss: 1.1914180517196655\n",
      "Epoch 87 | Loss: 1.191275954246521\n",
      "Epoch 88 | Loss: 1.1946252584457397\n",
      "Epoch 89 | Loss: 1.1865962743759155\n",
      "Epoch 90 | Loss: 1.184402585029602\n",
      "Epoch 91 | Loss: 1.193254828453064\n",
      "Epoch 92 | Loss: 1.186174988746643\n",
      "Epoch 93 | Loss: 1.1879674196243286\n",
      "Epoch 94 | Loss: 1.1831899881362915\n",
      "Epoch 95 | Loss: 1.1900361776351929\n",
      "Epoch 96 | Loss: 1.191740870475769\n",
      "Epoch 97 | Loss: 1.1765702962875366\n",
      "Epoch 98 | Loss: 1.1793216466903687\n",
      "Epoch 99 | Loss: 1.1774678230285645\n",
      "Epoch 100 | Loss: 1.1761428117752075\n",
      "Epoch 101 | Loss: 1.184169054031372\n",
      "Epoch 102 | Loss: 1.182496190071106\n",
      "Epoch 103 | Loss: 1.177620530128479\n",
      "Epoch 104 | Loss: 1.1790226697921753\n",
      "Epoch 105 | Loss: 1.1812081336975098\n",
      "Epoch 106 | Loss: 1.181647539138794\n",
      "Epoch 107 | Loss: 1.182755947113037\n",
      "Epoch 108 | Loss: 1.1733171939849854\n",
      "Epoch 109 | Loss: 1.1771996021270752\n",
      "Epoch 110 | Loss: 1.1732633113861084\n",
      "Epoch 111 | Loss: 1.1747136116027832\n",
      "Epoch 112 | Loss: 1.1712347269058228\n",
      "Epoch 113 | Loss: 1.1745058298110962\n",
      "Epoch 114 | Loss: 1.1710712909698486\n",
      "Epoch 115 | Loss: 1.1712791919708252\n",
      "Epoch 116 | Loss: 1.170577883720398\n",
      "Epoch 117 | Loss: 1.1724209785461426\n",
      "Epoch 118 | Loss: 1.1739469766616821\n",
      "Epoch 119 | Loss: 1.1697943210601807\n",
      "Epoch 120 | Loss: 1.1721683740615845\n",
      "Epoch 121 | Loss: 1.1750245094299316\n",
      "Epoch 122 | Loss: 1.1722946166992188\n",
      "Epoch 123 | Loss: 1.1709871292114258\n",
      "Epoch 124 | Loss: 1.1741623878479004\n",
      "Epoch 125 | Loss: 1.1732875108718872\n",
      "Epoch 126 | Loss: 1.1733158826828003\n",
      "Epoch 127 | Loss: 1.1696786880493164\n",
      "Epoch 128 | Loss: 1.16898775100708\n",
      "Epoch 129 | Loss: 1.1822621822357178\n",
      "Epoch 130 | Loss: 1.1712093353271484\n",
      "Epoch 131 | Loss: 1.1736658811569214\n",
      "Epoch 132 | Loss: 1.1684530973434448\n",
      "Epoch 133 | Loss: 1.1702690124511719\n",
      "Epoch 134 | Loss: 1.1716128587722778\n",
      "Epoch 135 | Loss: 1.1770210266113281\n",
      "Epoch 136 | Loss: 1.1745561361312866\n",
      "Epoch 137 | Loss: 1.1726230382919312\n",
      "Epoch 138 | Loss: 1.1692707538604736\n",
      "Epoch 139 | Loss: 1.168379306793213\n",
      "Epoch 140 | Loss: 1.169229507446289\n",
      "Epoch 141 | Loss: 1.171067476272583\n",
      "Epoch 142 | Loss: 1.1674652099609375\n",
      "Epoch 143 | Loss: 1.167972207069397\n",
      "Epoch 144 | Loss: 1.1703848838806152\n",
      "Epoch 145 | Loss: 1.1700172424316406\n",
      "Epoch 146 | Loss: 1.168052077293396\n",
      "Epoch 147 | Loss: 1.167720913887024\n",
      "Epoch 148 | Loss: 1.1703317165374756\n",
      "Epoch 149 | Loss: 1.1694060564041138\n",
      "Epoch 150 | Loss: 1.1681827306747437\n",
      "Epoch 151 | Loss: 1.167922019958496\n",
      "Epoch 152 | Loss: 1.167331337928772\n",
      "Epoch 153 | Loss: 1.1694761514663696\n",
      "Epoch 154 | Loss: 1.1689599752426147\n",
      "Epoch 155 | Loss: 1.1680376529693604\n",
      "Epoch 156 | Loss: 1.167242169380188\n",
      "Epoch 157 | Loss: 1.1673057079315186\n",
      "Epoch 158 | Loss: 1.167411208152771\n",
      "Epoch 159 | Loss: 1.1683694124221802\n",
      "Epoch 160 | Loss: 1.1680424213409424\n",
      "Epoch 161 | Loss: 1.1676520109176636\n",
      "Epoch 162 | Loss: 1.1677684783935547\n",
      "Epoch 163 | Loss: 1.167839765548706\n",
      "Epoch 164 | Loss: 1.1684038639068604\n",
      "Epoch 165 | Loss: 1.167883038520813\n",
      "Epoch 166 | Loss: 1.1681456565856934\n",
      "Epoch 167 | Loss: 1.1679553985595703\n",
      "Epoch 168 | Loss: 1.1669796705245972\n",
      "Epoch 169 | Loss: 1.1728984117507935\n",
      "Epoch 170 | Loss: 1.1694509983062744\n",
      "Epoch 171 | Loss: 1.1679459810256958\n",
      "Epoch 172 | Loss: 1.1667273044586182\n",
      "Epoch 173 | Loss: 1.166322112083435\n",
      "Epoch 174 | Loss: 1.1664739847183228\n",
      "Epoch 175 | Loss: 1.1667320728302002\n",
      "Epoch 176 | Loss: 1.1684658527374268\n",
      "Epoch 177 | Loss: 1.1684595346450806\n",
      "Epoch 178 | Loss: 1.1696809530258179\n",
      "Epoch 179 | Loss: 1.169143795967102\n",
      "Epoch 180 | Loss: 1.1674606800079346\n",
      "Epoch 181 | Loss: 1.169458270072937\n",
      "Epoch 182 | Loss: 1.1665431261062622\n",
      "Epoch 183 | Loss: 1.166664719581604\n",
      "Epoch 184 | Loss: 1.166996955871582\n",
      "Epoch 185 | Loss: 1.1666613817214966\n",
      "Epoch 186 | Loss: 1.1674093008041382\n",
      "Epoch 187 | Loss: 1.1691068410873413\n",
      "Epoch 188 | Loss: 1.1671922206878662\n",
      "Epoch 189 | Loss: 1.166562795639038\n",
      "Epoch 190 | Loss: 1.1667683124542236\n",
      "Epoch 191 | Loss: 1.166958212852478\n",
      "Epoch 192 | Loss: 1.1681649684906006\n",
      "Epoch 193 | Loss: 1.1670706272125244\n",
      "Epoch 194 | Loss: 1.1668031215667725\n",
      "Epoch 195 | Loss: 1.1667841672897339\n",
      "Epoch 196 | Loss: 1.1673177480697632\n",
      "Epoch 197 | Loss: 1.1663358211517334\n",
      "Epoch 198 | Loss: 1.1672776937484741\n",
      "Epoch 199 | Loss: 1.1719608306884766\n",
      "Epoch 200 | Loss: 1.1664117574691772\n",
      "Epoch 201 | Loss: 1.1669328212738037\n",
      "Epoch 202 | Loss: 1.1670457124710083\n",
      "Epoch 203 | Loss: 1.1662886142730713\n",
      "Epoch 204 | Loss: 1.166810393333435\n",
      "Epoch 205 | Loss: 1.1663440465927124\n",
      "Epoch 206 | Loss: 1.1662129163742065\n",
      "Epoch 207 | Loss: 1.1663655042648315\n",
      "Epoch 208 | Loss: 1.1668927669525146\n",
      "Epoch 209 | Loss: 1.167575716972351\n",
      "Epoch 210 | Loss: 1.1687664985656738\n",
      "Epoch 211 | Loss: 1.166768193244934\n",
      "Epoch 212 | Loss: 1.1668542623519897\n",
      "Epoch 213 | Loss: 1.1667054891586304\n",
      "Epoch 214 | Loss: 1.1677751541137695\n",
      "Epoch 215 | Loss: 1.1667542457580566\n",
      "Epoch 216 | Loss: 1.1668927669525146\n",
      "Epoch 217 | Loss: 1.1664667129516602\n",
      "Epoch 218 | Loss: 1.1663447618484497\n",
      "Epoch 219 | Loss: 1.1662813425064087\n",
      "Epoch 220 | Loss: 1.167410969734192\n",
      "Epoch 221 | Loss: 1.1667814254760742\n",
      "Epoch 222 | Loss: 1.1659722328186035\n",
      "Epoch 223 | Loss: 1.1660059690475464\n",
      "Epoch 224 | Loss: 1.167229175567627\n",
      "Epoch 225 | Loss: 1.1667853593826294\n",
      "Epoch 226 | Loss: 1.173467993736267\n",
      "Epoch 227 | Loss: 1.1683415174484253\n",
      "Epoch 228 | Loss: 1.166365146636963\n",
      "Epoch 229 | Loss: 1.1664663553237915\n",
      "Epoch 230 | Loss: 1.1664739847183228\n",
      "Epoch 231 | Loss: 1.1660476922988892\n",
      "Epoch 232 | Loss: 1.167689561843872\n",
      "Epoch 233 | Loss: 1.1661899089813232\n",
      "Epoch 234 | Loss: 1.1660823822021484\n",
      "Epoch 235 | Loss: 1.1662250757217407\n",
      "Epoch 236 | Loss: 1.1678242683410645\n",
      "Epoch 237 | Loss: 1.1672385931015015\n",
      "Epoch 238 | Loss: 1.166212797164917\n",
      "Epoch 239 | Loss: 1.1665446758270264\n",
      "Epoch 240 | Loss: 1.1662439107894897\n",
      "Epoch 241 | Loss: 1.1661325693130493\n",
      "Epoch 242 | Loss: 1.166107416152954\n",
      "Epoch 243 | Loss: 1.1668546199798584\n",
      "Epoch 244 | Loss: 1.1666024923324585\n",
      "Epoch 245 | Loss: 1.1662259101867676\n",
      "Epoch 246 | Loss: 1.1671339273452759\n",
      "Epoch 247 | Loss: 1.1663252115249634\n",
      "Epoch 248 | Loss: 1.165953278541565\n",
      "Epoch 249 | Loss: 1.1659232378005981\n",
      "Epoch 250 | Loss: 1.1657623052597046\n",
      "Epoch 251 | Loss: 1.1662194728851318\n",
      "Epoch 252 | Loss: 1.1662766933441162\n",
      "Epoch 253 | Loss: 1.1669477224349976\n",
      "Epoch 254 | Loss: 1.1661274433135986\n",
      "Epoch 255 | Loss: 1.166060447692871\n",
      "Epoch 256 | Loss: 1.165921688079834\n",
      "Epoch 257 | Loss: 1.165968418121338\n",
      "Epoch 258 | Loss: 1.1660715341567993\n",
      "Epoch 259 | Loss: 1.1658483743667603\n",
      "Epoch 260 | Loss: 1.166168212890625\n",
      "Epoch 261 | Loss: 1.165818214416504\n",
      "Epoch 262 | Loss: 1.166006088256836\n",
      "Epoch 263 | Loss: 1.1663519144058228\n",
      "Epoch 264 | Loss: 1.1666488647460938\n",
      "Epoch 265 | Loss: 1.1661418676376343\n",
      "Epoch 266 | Loss: 1.1664024591445923\n",
      "Epoch 267 | Loss: 1.166299819946289\n",
      "Epoch 268 | Loss: 1.1669530868530273\n",
      "Epoch 269 | Loss: 1.1665897369384766\n",
      "Epoch 270 | Loss: 1.1660890579223633\n",
      "Epoch 271 | Loss: 1.1661853790283203\n",
      "Epoch 272 | Loss: 1.166479468345642\n",
      "Epoch 273 | Loss: 1.1664708852767944\n",
      "Epoch 274 | Loss: 1.1658955812454224\n",
      "Epoch 275 | Loss: 1.1660690307617188\n",
      "Epoch 276 | Loss: 1.1663341522216797\n",
      "Epoch 277 | Loss: 1.165749430656433\n",
      "Epoch 278 | Loss: 1.1659072637557983\n",
      "Epoch 279 | Loss: 1.16627037525177\n",
      "Epoch 280 | Loss: 1.1662085056304932\n",
      "Epoch 281 | Loss: 1.166009545326233\n",
      "Epoch 282 | Loss: 1.166038155555725\n",
      "Epoch 283 | Loss: 1.1662399768829346\n",
      "Epoch 284 | Loss: 1.165940284729004\n",
      "Epoch 285 | Loss: 1.1660205125808716\n",
      "Epoch 286 | Loss: 1.165978193283081\n",
      "Epoch 287 | Loss: 1.166099190711975\n",
      "Epoch 288 | Loss: 1.1660161018371582\n",
      "Epoch 289 | Loss: 1.1659092903137207\n",
      "Epoch 290 | Loss: 1.1659730672836304\n",
      "Epoch 291 | Loss: 1.1658506393432617\n",
      "Epoch 292 | Loss: 1.1671850681304932\n",
      "Epoch 293 | Loss: 1.1665771007537842\n",
      "Epoch 294 | Loss: 1.1661288738250732\n",
      "Epoch 295 | Loss: 1.1660212278366089\n",
      "Epoch 296 | Loss: 1.166724681854248\n",
      "Epoch 297 | Loss: 1.1660046577453613\n",
      "Epoch 298 | Loss: 1.1659599542617798\n",
      "Epoch 299 | Loss: 1.165906548500061\n",
      "Epoch 300 | Loss: 1.1662235260009766\n",
      "Epoch 301 | Loss: 1.1669105291366577\n",
      "Epoch 302 | Loss: 1.1658445596694946\n",
      "Epoch 303 | Loss: 1.1658114194869995\n",
      "Epoch 304 | Loss: 1.1658447980880737\n",
      "Epoch 305 | Loss: 1.1658991575241089\n",
      "Epoch 306 | Loss: 1.165906310081482\n",
      "Epoch 307 | Loss: 1.1659969091415405\n",
      "Epoch 308 | Loss: 1.166070818901062\n",
      "Epoch 309 | Loss: 1.165878176689148\n",
      "Epoch 310 | Loss: 1.16591215133667\n",
      "Epoch 311 | Loss: 1.1658238172531128\n",
      "Epoch 312 | Loss: 1.165945053100586\n",
      "Epoch 313 | Loss: 1.1657500267028809\n",
      "Epoch 314 | Loss: 1.1660492420196533\n",
      "Epoch 315 | Loss: 1.1659551858901978\n",
      "Epoch 316 | Loss: 1.166231393814087\n",
      "Epoch 317 | Loss: 1.1660107374191284\n",
      "Epoch 318 | Loss: 1.166094422340393\n",
      "Epoch 319 | Loss: 1.1660363674163818\n",
      "Epoch 320 | Loss: 1.165891408920288\n",
      "Epoch 321 | Loss: 1.166721224784851\n",
      "Epoch 322 | Loss: 1.1660031080245972\n",
      "Epoch 323 | Loss: 1.1660687923431396\n",
      "Epoch 324 | Loss: 1.165891170501709\n",
      "Epoch 325 | Loss: 1.1656767129898071\n",
      "Epoch 326 | Loss: 1.1662712097167969\n",
      "Epoch 327 | Loss: 1.165706753730774\n",
      "Epoch 328 | Loss: 1.1659889221191406\n",
      "Epoch 329 | Loss: 1.1657519340515137\n",
      "Epoch 330 | Loss: 1.1658862829208374\n",
      "Epoch 331 | Loss: 1.1660072803497314\n",
      "Epoch 332 | Loss: 1.1660583019256592\n",
      "Epoch 333 | Loss: 1.1656867265701294\n",
      "Epoch 334 | Loss: 1.1659114360809326\n",
      "Epoch 335 | Loss: 1.166222095489502\n",
      "Epoch 336 | Loss: 1.1657196283340454\n",
      "Epoch 337 | Loss: 1.1658685207366943\n",
      "Epoch 338 | Loss: 1.165796160697937\n",
      "Epoch 339 | Loss: 1.165937066078186\n",
      "Epoch 340 | Loss: 1.1673698425292969\n",
      "Epoch 341 | Loss: 1.1659798622131348\n",
      "Epoch 342 | Loss: 1.1672101020812988\n",
      "Epoch 343 | Loss: 1.166186809539795\n",
      "Epoch 344 | Loss: 1.1657533645629883\n",
      "Epoch 345 | Loss: 1.1656602621078491\n",
      "Epoch 346 | Loss: 1.1658467054367065\n",
      "Epoch 347 | Loss: 1.1658459901809692\n",
      "Epoch 348 | Loss: 1.1658496856689453\n",
      "Epoch 349 | Loss: 1.1656450033187866\n",
      "Epoch 350 | Loss: 1.1658118963241577\n",
      "Epoch 351 | Loss: 1.1657440662384033\n",
      "Epoch 352 | Loss: 1.1656079292297363\n",
      "Epoch 353 | Loss: 1.165907382965088\n",
      "Epoch 354 | Loss: 1.1657371520996094\n",
      "Epoch 355 | Loss: 1.1655724048614502\n",
      "Epoch 356 | Loss: 1.165663480758667\n",
      "Epoch 357 | Loss: 1.166010856628418\n",
      "Epoch 358 | Loss: 1.165735125541687\n",
      "Epoch 359 | Loss: 1.165700912475586\n",
      "Epoch 360 | Loss: 1.165769338607788\n",
      "Epoch 361 | Loss: 1.1657025814056396\n",
      "Epoch 362 | Loss: 1.165824294090271\n",
      "Epoch 363 | Loss: 1.1657212972640991\n",
      "Epoch 364 | Loss: 1.1656746864318848\n",
      "Epoch 365 | Loss: 1.1657118797302246\n",
      "Epoch 366 | Loss: 1.1655877828598022\n",
      "Epoch 367 | Loss: 1.1656551361083984\n",
      "Epoch 368 | Loss: 1.165563941001892\n",
      "Epoch 369 | Loss: 1.1657955646514893\n",
      "Epoch 370 | Loss: 1.165799856185913\n",
      "Epoch 371 | Loss: 1.165815830230713\n",
      "Epoch 372 | Loss: 1.1659209728240967\n",
      "Epoch 373 | Loss: 1.1657774448394775\n",
      "Epoch 374 | Loss: 1.166858196258545\n",
      "Epoch 375 | Loss: 1.1656231880187988\n",
      "Epoch 376 | Loss: 1.165694236755371\n",
      "Epoch 377 | Loss: 1.1657195091247559\n",
      "Epoch 378 | Loss: 1.1660126447677612\n",
      "Epoch 379 | Loss: 1.1661763191223145\n",
      "Epoch 380 | Loss: 1.1657241582870483\n",
      "Epoch 381 | Loss: 1.1658265590667725\n",
      "Epoch 382 | Loss: 1.1668919324874878\n",
      "Epoch 383 | Loss: 1.16669762134552\n",
      "Epoch 384 | Loss: 1.1668294668197632\n",
      "Epoch 385 | Loss: 1.1660035848617554\n",
      "Epoch 386 | Loss: 1.1655982732772827\n",
      "Epoch 387 | Loss: 1.1656690835952759\n",
      "Epoch 388 | Loss: 1.165683627128601\n",
      "Epoch 389 | Loss: 1.1658962965011597\n",
      "Epoch 390 | Loss: 1.1659038066864014\n",
      "Epoch 391 | Loss: 1.1663697957992554\n",
      "Epoch 392 | Loss: 1.1660195589065552\n",
      "Epoch 393 | Loss: 1.1657416820526123\n",
      "Epoch 394 | Loss: 1.165895700454712\n",
      "Epoch 395 | Loss: 1.1656006574630737\n",
      "Epoch 396 | Loss: 1.165869116783142\n",
      "Epoch 397 | Loss: 1.1657297611236572\n",
      "Epoch 398 | Loss: 1.1660842895507812\n",
      "Epoch 399 | Loss: 1.165648341178894\n",
      "Epoch 400 | Loss: 1.165814757347107\n",
      "Epoch 401 | Loss: 1.165994644165039\n",
      "Epoch 402 | Loss: 1.1657973527908325\n",
      "Epoch 403 | Loss: 1.165981650352478\n",
      "Epoch 404 | Loss: 1.1658306121826172\n",
      "Epoch 405 | Loss: 1.1656715869903564\n",
      "Epoch 406 | Loss: 1.1656361818313599\n",
      "Epoch 407 | Loss: 1.1657533645629883\n",
      "Epoch 408 | Loss: 1.1658512353897095\n",
      "Epoch 409 | Loss: 1.1657031774520874\n",
      "Epoch 410 | Loss: 1.1659107208251953\n",
      "Epoch 411 | Loss: 1.1656744480133057\n",
      "Epoch 412 | Loss: 1.1655853986740112\n",
      "Epoch 413 | Loss: 1.1660637855529785\n",
      "Epoch 414 | Loss: 1.1659824848175049\n",
      "Epoch 415 | Loss: 1.1658613681793213\n",
      "Epoch 416 | Loss: 1.1666237115859985\n",
      "Epoch 417 | Loss: 1.1656733751296997\n",
      "Epoch 418 | Loss: 1.1655540466308594\n",
      "Epoch 419 | Loss: 1.1655709743499756\n",
      "Epoch 420 | Loss: 1.1656581163406372\n",
      "Epoch 421 | Loss: 1.165847897529602\n",
      "Epoch 422 | Loss: 1.165649652481079\n",
      "Epoch 423 | Loss: 1.1662039756774902\n",
      "Epoch 424 | Loss: 1.165666937828064\n",
      "Epoch 425 | Loss: 1.1656147241592407\n",
      "Epoch 426 | Loss: 1.1655467748641968\n",
      "Epoch 427 | Loss: 1.1656267642974854\n",
      "Epoch 428 | Loss: 1.1656898260116577\n",
      "Epoch 429 | Loss: 1.1656155586242676\n",
      "Epoch 430 | Loss: 1.1661112308502197\n",
      "Epoch 431 | Loss: 1.166824221611023\n",
      "Epoch 432 | Loss: 1.1656488180160522\n",
      "Epoch 433 | Loss: 1.1659657955169678\n",
      "Epoch 434 | Loss: 1.165716528892517\n",
      "Epoch 435 | Loss: 1.1656285524368286\n",
      "Epoch 436 | Loss: 1.1655761003494263\n",
      "Epoch 437 | Loss: 1.1656907796859741\n",
      "Epoch 438 | Loss: 1.1656794548034668\n",
      "Epoch 439 | Loss: 1.1657873392105103\n",
      "Epoch 440 | Loss: 1.165571689605713\n",
      "Epoch 441 | Loss: 1.1656502485275269\n",
      "Epoch 442 | Loss: 1.165596604347229\n",
      "Epoch 443 | Loss: 1.1656696796417236\n",
      "Epoch 444 | Loss: 1.1656455993652344\n",
      "Epoch 445 | Loss: 1.1658464670181274\n",
      "Epoch 446 | Loss: 1.1656196117401123\n",
      "Epoch 447 | Loss: 1.1660215854644775\n",
      "Epoch 448 | Loss: 1.1657718420028687\n",
      "Epoch 449 | Loss: 1.1655793190002441\n",
      "Epoch 450 | Loss: 1.1658166646957397\n",
      "Epoch 451 | Loss: 1.1657456159591675\n",
      "Epoch 452 | Loss: 1.166223406791687\n",
      "Epoch 453 | Loss: 1.1655865907669067\n",
      "Epoch 454 | Loss: 1.1656900644302368\n",
      "Epoch 455 | Loss: 1.165545105934143\n",
      "Epoch 456 | Loss: 1.1656678915023804\n",
      "Epoch 457 | Loss: 1.1657075881958008\n",
      "Epoch 458 | Loss: 1.1656371355056763\n",
      "Epoch 459 | Loss: 1.1655800342559814\n",
      "Epoch 460 | Loss: 1.1655561923980713\n",
      "Epoch 461 | Loss: 1.1656452417373657\n",
      "Epoch 462 | Loss: 1.165693998336792\n",
      "Epoch 463 | Loss: 1.1656841039657593\n",
      "Epoch 464 | Loss: 1.1655452251434326\n",
      "Epoch 465 | Loss: 1.1657905578613281\n",
      "Epoch 466 | Loss: 1.165749192237854\n",
      "Epoch 467 | Loss: 1.165575385093689\n",
      "Epoch 468 | Loss: 1.165573000907898\n",
      "Epoch 469 | Loss: 1.166448950767517\n",
      "Epoch 470 | Loss: 1.1657453775405884\n",
      "Epoch 471 | Loss: 1.165597677230835\n",
      "Epoch 472 | Loss: 1.1656948328018188\n",
      "Epoch 473 | Loss: 1.1656807661056519\n",
      "Epoch 474 | Loss: 1.1656333208084106\n",
      "Epoch 475 | Loss: 1.165502667427063\n",
      "Epoch 476 | Loss: 1.1656843423843384\n",
      "Epoch 477 | Loss: 1.1660085916519165\n",
      "Epoch 478 | Loss: 1.165572166442871\n",
      "Epoch 479 | Loss: 1.1656008958816528\n",
      "Epoch 480 | Loss: 1.1655937433242798\n",
      "Epoch 481 | Loss: 1.1656475067138672\n",
      "Epoch 482 | Loss: 1.1657283306121826\n",
      "Epoch 483 | Loss: 1.1655848026275635\n",
      "Epoch 484 | Loss: 1.1655821800231934\n",
      "Epoch 485 | Loss: 1.1655853986740112\n",
      "Epoch 486 | Loss: 1.1657638549804688\n",
      "Epoch 487 | Loss: 1.1655532121658325\n",
      "Epoch 488 | Loss: 1.1657211780548096\n",
      "Epoch 489 | Loss: 1.165626049041748\n",
      "Epoch 490 | Loss: 1.1656264066696167\n",
      "Epoch 491 | Loss: 1.1655678749084473\n",
      "Epoch 492 | Loss: 1.1657495498657227\n",
      "Epoch 493 | Loss: 1.165596604347229\n",
      "Epoch 494 | Loss: 1.1656380891799927\n",
      "Epoch 495 | Loss: 1.165916919708252\n",
      "Epoch 496 | Loss: 1.1656301021575928\n",
      "Epoch 497 | Loss: 1.166322946548462\n",
      "Epoch 498 | Loss: 1.165562629699707\n",
      "Epoch 499 | Loss: 1.1661180257797241\n",
      "Epoch 500 | Loss: 1.165566086769104\n",
      "Epoch 501 | Loss: 1.165596604347229\n",
      "Epoch 502 | Loss: 1.165847897529602\n",
      "Epoch 503 | Loss: 1.1656147241592407\n",
      "Epoch 504 | Loss: 1.165719747543335\n",
      "Epoch 505 | Loss: 1.1656506061553955\n",
      "Epoch 506 | Loss: 1.1656363010406494\n",
      "Epoch 507 | Loss: 1.1656427383422852\n",
      "Epoch 508 | Loss: 1.1658005714416504\n",
      "Epoch 509 | Loss: 1.1657509803771973\n",
      "Epoch 510 | Loss: 1.1655194759368896\n",
      "Epoch 511 | Loss: 1.1655631065368652\n",
      "Epoch 512 | Loss: 1.1656267642974854\n",
      "Epoch 513 | Loss: 1.1656488180160522\n",
      "Epoch 514 | Loss: 1.165839433670044\n",
      "Epoch 515 | Loss: 1.1655101776123047\n",
      "Epoch 516 | Loss: 1.1656180620193481\n",
      "Epoch 517 | Loss: 1.1656420230865479\n",
      "Epoch 518 | Loss: 1.1655151844024658\n",
      "Epoch 519 | Loss: 1.1655633449554443\n",
      "Epoch 520 | Loss: 1.1656311750411987\n",
      "Epoch 521 | Loss: 1.165669322013855\n",
      "Epoch 522 | Loss: 1.16636323928833\n",
      "Epoch 523 | Loss: 1.1655941009521484\n",
      "Epoch 524 | Loss: 1.1658306121826172\n",
      "Epoch 525 | Loss: 1.1657066345214844\n",
      "Epoch 526 | Loss: 1.165655493736267\n",
      "Epoch 527 | Loss: 1.1658085584640503\n",
      "Epoch 528 | Loss: 1.1655861139297485\n",
      "Epoch 529 | Loss: 1.1656241416931152\n",
      "Epoch 530 | Loss: 1.1655299663543701\n",
      "Epoch 531 | Loss: 1.165530800819397\n",
      "Epoch 532 | Loss: 1.1655815839767456\n",
      "Epoch 533 | Loss: 1.1655528545379639\n",
      "Epoch 534 | Loss: 1.1656749248504639\n",
      "Epoch 535 | Loss: 1.1655372381210327\n",
      "Epoch 536 | Loss: 1.1654638051986694\n",
      "Epoch 537 | Loss: 1.1655306816101074\n",
      "Epoch 538 | Loss: 1.165555477142334\n",
      "Epoch 539 | Loss: 1.1711390018463135\n",
      "Epoch 540 | Loss: 1.1654809713363647\n",
      "Epoch 541 | Loss: 1.1656500101089478\n",
      "Epoch 542 | Loss: 1.1657675504684448\n",
      "Epoch 543 | Loss: 1.1658329963684082\n",
      "Epoch 544 | Loss: 1.1663748025894165\n",
      "Epoch 545 | Loss: 1.166573405265808\n",
      "Epoch 546 | Loss: 1.1687391996383667\n",
      "Epoch 547 | Loss: 1.1656662225723267\n",
      "Epoch 548 | Loss: 1.1656901836395264\n",
      "Epoch 549 | Loss: 1.1663858890533447\n",
      "Epoch 550 | Loss: 1.1656752824783325\n",
      "Epoch 551 | Loss: 1.1656935214996338\n",
      "Epoch 552 | Loss: 1.1655772924423218\n",
      "Epoch 553 | Loss: 1.165506362915039\n",
      "Epoch 554 | Loss: 1.166038155555725\n",
      "Epoch 555 | Loss: 1.1656758785247803\n",
      "Epoch 556 | Loss: 1.165703535079956\n",
      "Epoch 557 | Loss: 1.1659305095672607\n",
      "Epoch 558 | Loss: 1.1655430793762207\n",
      "Epoch 559 | Loss: 1.1656395196914673\n",
      "Epoch 560 | Loss: 1.1655962467193604\n",
      "Epoch 561 | Loss: 1.1655476093292236\n",
      "Epoch 562 | Loss: 1.1657403707504272\n",
      "Epoch 563 | Loss: 1.1656805276870728\n",
      "Epoch 564 | Loss: 1.1658477783203125\n",
      "Epoch 565 | Loss: 1.1657708883285522\n",
      "Epoch 566 | Loss: 1.1655702590942383\n",
      "Epoch 567 | Loss: 1.1657905578613281\n",
      "Epoch 568 | Loss: 1.165639877319336\n",
      "Epoch 569 | Loss: 1.165910005569458\n",
      "Epoch 570 | Loss: 1.1654914617538452\n",
      "Epoch 571 | Loss: 1.1655081510543823\n",
      "Epoch 572 | Loss: 1.1659663915634155\n",
      "Epoch 573 | Loss: 1.1662102937698364\n",
      "Epoch 574 | Loss: 1.1655547618865967\n",
      "Epoch 575 | Loss: 1.1655840873718262\n",
      "Epoch 576 | Loss: 1.1655516624450684\n",
      "Epoch 577 | Loss: 1.1688311100006104\n",
      "Epoch 578 | Loss: 1.1654707193374634\n",
      "Epoch 579 | Loss: 1.1655101776123047\n",
      "Epoch 580 | Loss: 1.1658598184585571\n",
      "Epoch 581 | Loss: 1.1657458543777466\n",
      "Epoch 582 | Loss: 1.1655970811843872\n",
      "Epoch 583 | Loss: 1.1656107902526855\n",
      "Epoch 584 | Loss: 1.1656161546707153\n",
      "Epoch 585 | Loss: 1.1655126810073853\n",
      "Epoch 586 | Loss: 1.1655292510986328\n",
      "Epoch 587 | Loss: 1.165665864944458\n",
      "Epoch 588 | Loss: 1.1656759977340698\n",
      "Epoch 589 | Loss: 1.1659586429595947\n",
      "Epoch 590 | Loss: 1.1655914783477783\n",
      "Epoch 591 | Loss: 1.1657307147979736\n",
      "Epoch 592 | Loss: 1.165514349937439\n",
      "Epoch 593 | Loss: 1.1655089855194092\n",
      "Epoch 594 | Loss: 1.165514349937439\n",
      "Epoch 595 | Loss: 1.1655458211898804\n",
      "Epoch 596 | Loss: 1.1655582189559937\n",
      "Epoch 597 | Loss: 1.1655192375183105\n",
      "Epoch 598 | Loss: 1.1655327081680298\n",
      "Epoch 599 | Loss: 1.165500283241272\n",
      "Epoch 600 | Loss: 1.165500283241272\n",
      "Epoch 601 | Loss: 1.16558039188385\n",
      "Epoch 602 | Loss: 1.1657289266586304\n",
      "Epoch 603 | Loss: 1.1655851602554321\n",
      "Epoch 604 | Loss: 1.1657352447509766\n",
      "Epoch 605 | Loss: 1.1656914949417114\n",
      "Epoch 606 | Loss: 1.165518879890442\n",
      "Epoch 607 | Loss: 1.165482997894287\n",
      "Epoch 608 | Loss: 1.1657105684280396\n",
      "Epoch 609 | Loss: 1.1655595302581787\n",
      "Epoch 610 | Loss: 1.1656221151351929\n",
      "Epoch 611 | Loss: 1.1655406951904297\n",
      "Epoch 612 | Loss: 1.1656450033187866\n",
      "Epoch 613 | Loss: 1.1655038595199585\n",
      "Epoch 614 | Loss: 1.165475845336914\n",
      "Epoch 615 | Loss: 1.1657034158706665\n",
      "Epoch 616 | Loss: 1.1656323671340942\n",
      "Epoch 617 | Loss: 1.1655910015106201\n",
      "Epoch 618 | Loss: 1.1655476093292236\n",
      "Epoch 619 | Loss: 1.1655281782150269\n",
      "Epoch 620 | Loss: 1.1654831171035767\n",
      "Epoch 621 | Loss: 1.1659119129180908\n",
      "Epoch 622 | Loss: 1.165654182434082\n",
      "Epoch 623 | Loss: 1.1655023097991943\n",
      "Epoch 624 | Loss: 1.1655217409133911\n",
      "Epoch 625 | Loss: 1.165626883506775\n",
      "Epoch 626 | Loss: 1.1655309200286865\n",
      "Epoch 627 | Loss: 1.1655364036560059\n",
      "Epoch 628 | Loss: 1.16552734375\n",
      "Epoch 629 | Loss: 1.165504813194275\n",
      "Epoch 630 | Loss: 1.1655229330062866\n",
      "Epoch 631 | Loss: 1.165976643562317\n",
      "Epoch 632 | Loss: 1.1654757261276245\n",
      "Epoch 633 | Loss: 1.1654859781265259\n",
      "Epoch 634 | Loss: 1.1655218601226807\n",
      "Epoch 635 | Loss: 1.1655981540679932\n",
      "Epoch 636 | Loss: 1.1655292510986328\n",
      "Epoch 637 | Loss: 1.1655611991882324\n",
      "Epoch 638 | Loss: 1.1655540466308594\n",
      "Epoch 639 | Loss: 1.1656683683395386\n",
      "Epoch 640 | Loss: 1.165528655052185\n",
      "Epoch 641 | Loss: 1.165601372718811\n",
      "Epoch 642 | Loss: 1.1654833555221558\n",
      "Epoch 643 | Loss: 1.165702223777771\n",
      "Epoch 644 | Loss: 1.1658430099487305\n",
      "Epoch 645 | Loss: 1.1655532121658325\n",
      "Epoch 646 | Loss: 1.1655128002166748\n",
      "Epoch 647 | Loss: 1.165492296218872\n",
      "Epoch 648 | Loss: 1.1654770374298096\n",
      "Epoch 649 | Loss: 1.1655025482177734\n",
      "Epoch 650 | Loss: 1.1656222343444824\n",
      "Epoch 651 | Loss: 1.1655555963516235\n",
      "Epoch 652 | Loss: 1.1654508113861084\n",
      "Epoch 653 | Loss: 1.1655720472335815\n",
      "Epoch 654 | Loss: 1.1655505895614624\n",
      "Epoch 655 | Loss: 1.1654666662216187\n",
      "Epoch 656 | Loss: 1.1656655073165894\n",
      "Epoch 657 | Loss: 1.1655765771865845\n",
      "Epoch 658 | Loss: 1.1654962301254272\n",
      "Epoch 659 | Loss: 1.1655511856079102\n",
      "Epoch 660 | Loss: 1.1658788919448853\n",
      "Epoch 661 | Loss: 1.1655105352401733\n",
      "Epoch 662 | Loss: 1.1655077934265137\n",
      "Epoch 663 | Loss: 1.16548752784729\n",
      "Epoch 664 | Loss: 1.1654669046401978\n",
      "Epoch 665 | Loss: 1.1655577421188354\n",
      "Epoch 666 | Loss: 1.1654564142227173\n",
      "Epoch 667 | Loss: 1.1654632091522217\n",
      "Epoch 668 | Loss: 1.165503740310669\n",
      "Epoch 669 | Loss: 1.1654657125473022\n",
      "Epoch 670 | Loss: 1.1654802560806274\n",
      "Epoch 671 | Loss: 1.1655179262161255\n",
      "Epoch 672 | Loss: 1.1656118631362915\n",
      "Epoch 673 | Loss: 1.1655786037445068\n",
      "Epoch 674 | Loss: 1.1654777526855469\n",
      "Epoch 675 | Loss: 1.1654934883117676\n",
      "Epoch 676 | Loss: 1.1654542684555054\n",
      "Epoch 677 | Loss: 1.165468454360962\n",
      "Epoch 678 | Loss: 1.1655522584915161\n",
      "Epoch 679 | Loss: 1.1660182476043701\n",
      "Epoch 680 | Loss: 1.1656339168548584\n",
      "Epoch 681 | Loss: 1.1654791831970215\n",
      "Epoch 682 | Loss: 1.1654560565948486\n",
      "Epoch 683 | Loss: 1.1656575202941895\n",
      "Epoch 684 | Loss: 1.1654711961746216\n",
      "Epoch 685 | Loss: 1.1654757261276245\n",
      "Epoch 686 | Loss: 1.1655006408691406\n",
      "Epoch 687 | Loss: 1.1659514904022217\n",
      "Epoch 688 | Loss: 1.1654832363128662\n",
      "Epoch 689 | Loss: 1.165502905845642\n",
      "Epoch 690 | Loss: 1.165488362312317\n",
      "Epoch 691 | Loss: 1.16554856300354\n",
      "Epoch 692 | Loss: 1.1657418012619019\n",
      "Epoch 693 | Loss: 1.1655604839324951\n",
      "Epoch 694 | Loss: 1.165501594543457\n",
      "Epoch 695 | Loss: 1.165482759475708\n",
      "Epoch 696 | Loss: 1.1656523942947388\n",
      "Epoch 697 | Loss: 1.1654657125473022\n",
      "Epoch 698 | Loss: 1.165522575378418\n",
      "Epoch 699 | Loss: 1.1654727458953857\n",
      "Epoch 700 | Loss: 1.1654956340789795\n",
      "Epoch 701 | Loss: 1.1654860973358154\n",
      "Epoch 702 | Loss: 1.1656142473220825\n",
      "Epoch 703 | Loss: 1.1655280590057373\n",
      "Epoch 704 | Loss: 1.1654895544052124\n",
      "Epoch 705 | Loss: 1.1655089855194092\n",
      "Epoch 706 | Loss: 1.1657301187515259\n",
      "Epoch 707 | Loss: 1.165566086769104\n",
      "Epoch 708 | Loss: 1.1654748916625977\n",
      "Epoch 709 | Loss: 1.1655093431472778\n",
      "Epoch 710 | Loss: 1.1654795408248901\n",
      "Epoch 711 | Loss: 1.1654630899429321\n",
      "Epoch 712 | Loss: 1.1654891967773438\n",
      "Epoch 713 | Loss: 1.1654781103134155\n",
      "Epoch 714 | Loss: 1.1654902696609497\n",
      "Epoch 715 | Loss: 1.1654791831970215\n",
      "Epoch 716 | Loss: 1.1655136346817017\n",
      "Epoch 717 | Loss: 1.1655317544937134\n",
      "Epoch 718 | Loss: 1.1654998064041138\n",
      "Epoch 719 | Loss: 1.1654731035232544\n",
      "Epoch 720 | Loss: 1.1654490232467651\n",
      "Epoch 721 | Loss: 1.1654702425003052\n",
      "Epoch 722 | Loss: 1.165560245513916\n",
      "Epoch 723 | Loss: 1.165565848350525\n",
      "Epoch 724 | Loss: 1.1654787063598633\n",
      "Epoch 725 | Loss: 1.1654998064041138\n",
      "Epoch 726 | Loss: 1.1656100749969482\n",
      "Epoch 727 | Loss: 1.165541410446167\n",
      "Epoch 728 | Loss: 1.1656088829040527\n",
      "Epoch 729 | Loss: 1.1655771732330322\n",
      "Epoch 730 | Loss: 1.1655596494674683\n",
      "Epoch 731 | Loss: 1.1655175685882568\n",
      "Epoch 732 | Loss: 1.165597677230835\n",
      "Epoch 733 | Loss: 1.1655558347702026\n",
      "Epoch 734 | Loss: 1.1654913425445557\n",
      "Epoch 735 | Loss: 1.1654703617095947\n",
      "Epoch 736 | Loss: 1.1655863523483276\n",
      "Epoch 737 | Loss: 1.1655339002609253\n",
      "Epoch 738 | Loss: 1.1654552221298218\n",
      "Epoch 739 | Loss: 1.165536880493164\n",
      "Epoch 740 | Loss: 1.1654685735702515\n",
      "Epoch 741 | Loss: 1.1654731035232544\n",
      "Epoch 742 | Loss: 1.1655445098876953\n",
      "Epoch 743 | Loss: 1.1655317544937134\n",
      "Epoch 744 | Loss: 1.1654648780822754\n",
      "Epoch 745 | Loss: 1.1654971837997437\n",
      "Epoch 746 | Loss: 1.165553092956543\n",
      "Epoch 747 | Loss: 1.1655502319335938\n",
      "Epoch 748 | Loss: 1.1655468940734863\n",
      "Epoch 749 | Loss: 1.1654839515686035\n",
      "Epoch 750 | Loss: 1.1654525995254517\n",
      "Epoch 751 | Loss: 1.1654891967773438\n",
      "Epoch 752 | Loss: 1.165468454360962\n",
      "Epoch 753 | Loss: 1.1657263040542603\n",
      "Epoch 754 | Loss: 1.16554856300354\n",
      "Epoch 755 | Loss: 1.1655638217926025\n",
      "Epoch 756 | Loss: 1.1654589176177979\n",
      "Epoch 757 | Loss: 1.1655311584472656\n",
      "Epoch 758 | Loss: 1.165511965751648\n",
      "Epoch 759 | Loss: 1.165456771850586\n",
      "Epoch 760 | Loss: 1.1654466390609741\n",
      "Epoch 761 | Loss: 1.1654707193374634\n",
      "Epoch 762 | Loss: 1.1655141115188599\n",
      "Epoch 763 | Loss: 1.1654706001281738\n",
      "Epoch 764 | Loss: 1.1655292510986328\n",
      "Epoch 765 | Loss: 1.1655000448226929\n",
      "Epoch 766 | Loss: 1.1655546426773071\n",
      "Epoch 767 | Loss: 1.1655446290969849\n",
      "Epoch 768 | Loss: 1.1654715538024902\n",
      "Epoch 769 | Loss: 1.1654850244522095\n",
      "Epoch 770 | Loss: 1.165502905845642\n",
      "Epoch 771 | Loss: 1.1655559539794922\n",
      "Epoch 772 | Loss: 1.165475845336914\n",
      "Epoch 773 | Loss: 1.1655031442642212\n",
      "Epoch 774 | Loss: 1.1654658317565918\n",
      "Epoch 775 | Loss: 1.1655954122543335\n",
      "Epoch 776 | Loss: 1.165468692779541\n",
      "Epoch 777 | Loss: 1.1654601097106934\n",
      "Epoch 778 | Loss: 1.1654562950134277\n",
      "Epoch 779 | Loss: 1.1656090021133423\n",
      "Epoch 780 | Loss: 1.1654938459396362\n",
      "Epoch 781 | Loss: 1.1655924320220947\n",
      "Epoch 782 | Loss: 1.165460228919983\n",
      "Epoch 783 | Loss: 1.1654728651046753\n",
      "Epoch 784 | Loss: 1.1655603647232056\n",
      "Epoch 785 | Loss: 1.1654549837112427\n",
      "Epoch 786 | Loss: 1.1655833721160889\n",
      "Epoch 787 | Loss: 1.1654542684555054\n",
      "Epoch 788 | Loss: 1.1654736995697021\n",
      "Epoch 789 | Loss: 1.1655266284942627\n",
      "Epoch 790 | Loss: 1.1654666662216187\n",
      "Epoch 791 | Loss: 1.1654630899429321\n",
      "Epoch 792 | Loss: 1.1656253337860107\n",
      "Epoch 793 | Loss: 1.1654797792434692\n",
      "Epoch 794 | Loss: 1.1654393672943115\n",
      "Epoch 795 | Loss: 1.1654490232467651\n",
      "Epoch 796 | Loss: 1.1654764413833618\n",
      "Epoch 797 | Loss: 1.165497064590454\n",
      "Epoch 798 | Loss: 1.1654834747314453\n",
      "Epoch 799 | Loss: 1.1654596328735352\n",
      "Epoch 800 | Loss: 1.1655499935150146\n",
      "Epoch 801 | Loss: 1.165495753288269\n",
      "Epoch 802 | Loss: 1.1654613018035889\n",
      "Epoch 803 | Loss: 1.1659992933273315\n",
      "Epoch 804 | Loss: 1.1654542684555054\n",
      "Epoch 805 | Loss: 1.1654582023620605\n",
      "Epoch 806 | Loss: 1.165450096130371\n",
      "Epoch 807 | Loss: 1.165503740310669\n",
      "Epoch 808 | Loss: 1.1657347679138184\n",
      "Epoch 809 | Loss: 1.1654564142227173\n",
      "Epoch 810 | Loss: 1.165498971939087\n",
      "Epoch 811 | Loss: 1.1655558347702026\n",
      "Epoch 812 | Loss: 1.1655312776565552\n",
      "Epoch 813 | Loss: 1.1654835939407349\n",
      "Epoch 814 | Loss: 1.165450096130371\n",
      "Epoch 815 | Loss: 1.165501594543457\n",
      "Epoch 816 | Loss: 1.1654918193817139\n",
      "Epoch 817 | Loss: 1.1654444932937622\n",
      "Epoch 818 | Loss: 1.165485143661499\n",
      "Epoch 819 | Loss: 1.1654449701309204\n",
      "Epoch 820 | Loss: 1.165476679801941\n",
      "Epoch 821 | Loss: 1.1655324697494507\n",
      "Epoch 822 | Loss: 1.165452241897583\n",
      "Epoch 823 | Loss: 1.165542483329773\n",
      "Epoch 824 | Loss: 1.1654540300369263\n",
      "Epoch 825 | Loss: 1.165447473526001\n",
      "Epoch 826 | Loss: 1.1655954122543335\n",
      "Epoch 827 | Loss: 1.1654973030090332\n",
      "Epoch 828 | Loss: 1.1654727458953857\n",
      "Epoch 829 | Loss: 1.1654796600341797\n",
      "Epoch 830 | Loss: 1.1654788255691528\n",
      "Epoch 831 | Loss: 1.165448784828186\n",
      "Epoch 832 | Loss: 1.165473461151123\n",
      "Epoch 833 | Loss: 1.165582299232483\n",
      "Epoch 834 | Loss: 1.1654478311538696\n",
      "Epoch 835 | Loss: 1.1654962301254272\n",
      "Epoch 836 | Loss: 1.1655009984970093\n",
      "Epoch 837 | Loss: 1.1654560565948486\n",
      "Epoch 838 | Loss: 1.1654623746871948\n",
      "Epoch 839 | Loss: 1.1654720306396484\n",
      "Epoch 840 | Loss: 1.165472149848938\n",
      "Epoch 841 | Loss: 1.165486454963684\n",
      "Epoch 842 | Loss: 1.1654808521270752\n",
      "Epoch 843 | Loss: 1.165556788444519\n",
      "Epoch 844 | Loss: 1.165475845336914\n",
      "Epoch 845 | Loss: 1.1654771566390991\n",
      "Epoch 846 | Loss: 1.16545569896698\n",
      "Epoch 847 | Loss: 1.1654748916625977\n",
      "Epoch 848 | Loss: 1.165468692779541\n",
      "Epoch 849 | Loss: 1.165450096130371\n",
      "Epoch 850 | Loss: 1.1664749383926392\n",
      "Epoch 851 | Loss: 1.1654516458511353\n",
      "Epoch 852 | Loss: 1.165629267692566\n",
      "Epoch 853 | Loss: 1.1655232906341553\n",
      "Epoch 854 | Loss: 1.165447473526001\n",
      "Epoch 855 | Loss: 1.1655058860778809\n",
      "Epoch 856 | Loss: 1.1655292510986328\n",
      "Epoch 857 | Loss: 1.1655021905899048\n",
      "Epoch 858 | Loss: 1.1655322313308716\n",
      "Epoch 859 | Loss: 1.1656525135040283\n",
      "Epoch 860 | Loss: 1.1655621528625488\n",
      "Epoch 861 | Loss: 1.1655522584915161\n",
      "Epoch 862 | Loss: 1.1654912233352661\n",
      "Epoch 863 | Loss: 1.165472149848938\n",
      "Epoch 864 | Loss: 1.1654911041259766\n",
      "Epoch 865 | Loss: 1.1655261516571045\n",
      "Epoch 866 | Loss: 1.1655614376068115\n",
      "Epoch 867 | Loss: 1.1655538082122803\n",
      "Epoch 868 | Loss: 1.1655737161636353\n",
      "Epoch 869 | Loss: 1.1655008792877197\n",
      "Epoch 870 | Loss: 1.1655381917953491\n",
      "Epoch 871 | Loss: 1.1654738187789917\n",
      "Epoch 872 | Loss: 1.1655164957046509\n",
      "Epoch 873 | Loss: 1.1654822826385498\n",
      "Epoch 874 | Loss: 1.1654449701309204\n",
      "Epoch 875 | Loss: 1.1654678583145142\n",
      "Epoch 876 | Loss: 1.1657934188842773\n",
      "Epoch 877 | Loss: 1.1655422449111938\n",
      "Epoch 878 | Loss: 1.1656538248062134\n",
      "Epoch 879 | Loss: 1.165578007698059\n",
      "Epoch 880 | Loss: 1.165459394454956\n",
      "Epoch 881 | Loss: 1.165457010269165\n",
      "Epoch 882 | Loss: 1.1655327081680298\n",
      "Epoch 883 | Loss: 1.1654564142227173\n",
      "Epoch 884 | Loss: 1.165435552597046\n",
      "Epoch 885 | Loss: 1.1655722856521606\n",
      "Epoch 886 | Loss: 1.1654502153396606\n",
      "Epoch 887 | Loss: 1.1655352115631104\n",
      "Epoch 888 | Loss: 1.1655206680297852\n",
      "Epoch 889 | Loss: 1.165482759475708\n",
      "Epoch 890 | Loss: 1.1677745580673218\n",
      "Epoch 891 | Loss: 1.1654621362686157\n",
      "Epoch 892 | Loss: 1.1655927896499634\n",
      "Epoch 893 | Loss: 1.1655097007751465\n",
      "Epoch 894 | Loss: 1.165457010269165\n",
      "Epoch 895 | Loss: 1.1654385328292847\n",
      "Epoch 896 | Loss: 1.1654956340789795\n",
      "Epoch 897 | Loss: 1.1655315160751343\n",
      "Epoch 898 | Loss: 1.165486454963684\n",
      "Epoch 899 | Loss: 1.1654847860336304\n",
      "Epoch 900 | Loss: 1.1656526327133179\n",
      "Epoch 901 | Loss: 1.1658315658569336\n",
      "Epoch 902 | Loss: 1.1654976606369019\n",
      "Epoch 903 | Loss: 1.1655937433242798\n",
      "Epoch 904 | Loss: 1.165500521659851\n",
      "Epoch 905 | Loss: 1.1654655933380127\n",
      "Epoch 906 | Loss: 1.1654598712921143\n",
      "Epoch 907 | Loss: 1.165547251701355\n",
      "Epoch 908 | Loss: 1.1655147075653076\n",
      "Epoch 909 | Loss: 1.1654545068740845\n",
      "Epoch 910 | Loss: 1.165453314781189\n",
      "Epoch 911 | Loss: 1.1656032800674438\n",
      "Epoch 912 | Loss: 1.1654565334320068\n",
      "Epoch 913 | Loss: 1.16545832157135\n",
      "Epoch 914 | Loss: 1.1654607057571411\n",
      "Epoch 915 | Loss: 1.1654443740844727\n",
      "Epoch 916 | Loss: 1.1654510498046875\n",
      "Epoch 917 | Loss: 1.1654736995697021\n",
      "Epoch 918 | Loss: 1.1655136346817017\n",
      "Epoch 919 | Loss: 1.1654561758041382\n",
      "Epoch 920 | Loss: 1.1660157442092896\n",
      "Epoch 921 | Loss: 1.1655049324035645\n",
      "Epoch 922 | Loss: 1.1654423475265503\n",
      "Epoch 923 | Loss: 1.165627121925354\n",
      "Epoch 924 | Loss: 1.1654491424560547\n",
      "Epoch 925 | Loss: 1.1654690504074097\n",
      "Epoch 926 | Loss: 1.1654456853866577\n",
      "Epoch 927 | Loss: 1.1656084060668945\n",
      "Epoch 928 | Loss: 1.1654828786849976\n",
      "Epoch 929 | Loss: 1.1654633283615112\n",
      "Epoch 930 | Loss: 1.1655644178390503\n",
      "Epoch 931 | Loss: 1.1654927730560303\n",
      "Epoch 932 | Loss: 1.1654796600341797\n",
      "Epoch 933 | Loss: 1.1659170389175415\n",
      "Epoch 934 | Loss: 1.1656187772750854\n",
      "Epoch 935 | Loss: 1.165442705154419\n",
      "Epoch 936 | Loss: 1.165443778038025\n",
      "Epoch 937 | Loss: 1.1654443740844727\n",
      "Epoch 938 | Loss: 1.1655055284500122\n",
      "Epoch 939 | Loss: 1.1654958724975586\n",
      "Epoch 940 | Loss: 1.1654609441757202\n",
      "Epoch 941 | Loss: 1.1654728651046753\n",
      "Epoch 942 | Loss: 1.1654812097549438\n",
      "Epoch 943 | Loss: 1.1655210256576538\n",
      "Epoch 944 | Loss: 1.16546630859375\n",
      "Epoch 945 | Loss: 1.165488839149475\n",
      "Epoch 946 | Loss: 1.165455937385559\n",
      "Epoch 947 | Loss: 1.165439248085022\n",
      "Epoch 948 | Loss: 1.1654481887817383\n",
      "Epoch 949 | Loss: 1.165474772453308\n",
      "Epoch 950 | Loss: 1.1654456853866577\n",
      "Epoch 951 | Loss: 1.1654731035232544\n",
      "Epoch 952 | Loss: 1.165461540222168\n",
      "Epoch 953 | Loss: 1.1654618978500366\n",
      "Epoch 954 | Loss: 1.1654651165008545\n",
      "Epoch 955 | Loss: 1.165558099746704\n",
      "Epoch 956 | Loss: 1.165466070175171\n",
      "Epoch 957 | Loss: 1.165462851524353\n",
      "Epoch 958 | Loss: 1.165480375289917\n",
      "Epoch 959 | Loss: 1.1655235290527344\n",
      "Epoch 960 | Loss: 1.1654596328735352\n",
      "Epoch 961 | Loss: 1.1655069589614868\n",
      "Epoch 962 | Loss: 1.1655750274658203\n",
      "Epoch 963 | Loss: 1.1654595136642456\n",
      "Epoch 964 | Loss: 1.1654831171035767\n",
      "Epoch 965 | Loss: 1.1654646396636963\n",
      "Epoch 966 | Loss: 1.1654651165008545\n",
      "Epoch 967 | Loss: 1.1654889583587646\n",
      "Epoch 968 | Loss: 1.1654413938522339\n",
      "Epoch 969 | Loss: 1.1654784679412842\n",
      "Epoch 970 | Loss: 1.1654479503631592\n",
      "Epoch 971 | Loss: 1.165444016456604\n",
      "Epoch 972 | Loss: 1.1654605865478516\n",
      "Epoch 973 | Loss: 1.1655117273330688\n",
      "Epoch 974 | Loss: 1.1657637357711792\n",
      "Epoch 975 | Loss: 1.165548324584961\n",
      "Epoch 976 | Loss: 1.1654601097106934\n",
      "Epoch 977 | Loss: 1.1654589176177979\n",
      "Epoch 978 | Loss: 1.1655012369155884\n",
      "Epoch 979 | Loss: 1.1654558181762695\n",
      "Epoch 980 | Loss: 1.1654884815216064\n",
      "Epoch 981 | Loss: 1.1656208038330078\n",
      "Epoch 982 | Loss: 1.1654690504074097\n",
      "Epoch 983 | Loss: 1.1654423475265503\n",
      "Epoch 984 | Loss: 1.1654990911483765\n",
      "Epoch 985 | Loss: 1.165460228919983\n",
      "Epoch 986 | Loss: 1.1654400825500488\n",
      "Epoch 987 | Loss: 1.1659812927246094\n",
      "Epoch 988 | Loss: 1.1654682159423828\n",
      "Epoch 989 | Loss: 1.1654468774795532\n",
      "Epoch 990 | Loss: 1.1655246019363403\n",
      "Epoch 991 | Loss: 1.1654393672943115\n",
      "Epoch 992 | Loss: 1.1655439138412476\n",
      "Epoch 993 | Loss: 1.1654635667800903\n",
      "Epoch 994 | Loss: 1.165446400642395\n",
      "Epoch 995 | Loss: 1.1654646396636963\n",
      "Epoch 996 | Loss: 1.1654428243637085\n",
      "Epoch 997 | Loss: 1.1654411554336548\n",
      "Epoch 998 | Loss: 1.1654596328735352\n",
      "Epoch 999 | Loss: 1.1654937267303467\n",
      "Epoch 1000 | Loss: 1.1654720306396484\n"
     ]
    }
   ],
   "source": [
    "history = {\n",
    "  \"epoch\" : [],\n",
    "  \"loss\" : []\n",
    "}\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "  model.train()\n",
    "  optimizer.zero_grad()\n",
    "  out = model(dataset.x, dataset.edge_index)\n",
    "  loss = criterion(out[dataset.train_mask], dataset.y[dataset.train_mask])\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "  history[\"epoch\"].append(epoch)\n",
    "  history[\"loss\"].append(loss.cpu().detach().item())\n",
    "  \n",
    "  print(f\"Epoch {epoch} | Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x27daea8e0b0>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(history[\"epoch\"], history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7699999809265137\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "out = model(dataset.x, dataset.edge_index)\n",
    "pred = out.argmax(dim = 1)\n",
    "test_correct = pred[dataset.test_mask] == dataset.y[dataset.test_mask]\n",
    "accuracy = test_correct.sum() / dataset.test_mask.sum()\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
