{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from typing import List, Tuple\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch_geometric import data, nn\n",
    "import torch_geometric.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of possible 5 minutes in a days. Formula: 24 (hours) * 60 (minutes/hour) / 5 (minutes) = 288\n",
    "N_DAY_SLOT = (24 * 60) // 5\n",
    "config = {\n",
    "    \"F\": 12,\n",
    "    \"H\": 9,\n",
    "    \"N_DAYS\": 44,\n",
    "    \"N_DAY_SLOT\": N_DAY_SLOT,\n",
    "}\n",
    "\n",
    "config[\"N_SLOT\"] = config[\"N_DAY_SLOT\"] - (config[\"H\"] + config[\"F\"]) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Union\n",
    "\n",
    "\n",
    "class TrafficDataset(data.InMemoryDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: dict,\n",
    "        root: str,\n",
    "        gat_version: bool = True,\n",
    "        transform=None,\n",
    "        pre_transform=None,\n",
    "    ):\n",
    "        self.config = config\n",
    "        self.gat_version = gat_version\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "        (\n",
    "            self._data,\n",
    "            self._slice,\n",
    "            self._num_nodes,\n",
    "            self._mean,\n",
    "            self._std,\n",
    "        ) = torch.load(self.processed_paths[0])\n",
    "\n",
    "    # return the path of the file contains data which is processed\n",
    "    @property\n",
    "    def processed_file_names(self) -> str | List[str] | Tuple:\n",
    "        return [\"./data.pt\"]\n",
    "\n",
    "    # The path to the file contains data\n",
    "    @property\n",
    "    def raw_file_names(self) -> str | List[str] | Tuple:\n",
    "        return [\n",
    "            os.path.join(self.raw_dir, \"PeMSD7_V_228.csv\"),\n",
    "            os.path.join(self.raw_dir, \"PeMSD7_W_228.csv\"),\n",
    "        ]\n",
    "\n",
    "    # download the raw dataset file\n",
    "    def download(self):\n",
    "        V_dest = os.path.join(self.raw_dir, \"PeMSD7_V_228.csv\")\n",
    "        W_dest = os.path.join(self.raw_dir, \"PeMSD7_W_228.csv\")\n",
    "        shutil.copyfile(\"../data/raw/PeMSD7_V_228.csv\", V_dest)\n",
    "        shutil.copyfile(\"../data/raw/PeMSD7_W_228.csv\", W_dest)\n",
    "\n",
    "    def process(self):\n",
    "        df = pd.read_csv(self.raw_file_names[0], header=None)\n",
    "        weight_df = pd.read_csv(self.raw_file_names[1], header=None)\n",
    "        W = self._distance_to_weight(torch.from_numpy(weight_df.values))\n",
    "        data_ = torch.from_numpy(df.values)\n",
    "        mean = torch.mean(data_)\n",
    "        std = torch.std(data_)\n",
    "        _, num_nodes = data_.shape\n",
    "        edge_index = torch.zeros((2, num_nodes**2), dtype=torch.long)\n",
    "        edge_label = torch.zeros((num_nodes**2, 2))\n",
    "        num_edges = 0\n",
    "        # extract edge list from adjacency matrix\n",
    "        for i in range(num_nodes):\n",
    "            for j in range(num_nodes):\n",
    "                if W[i, j] != 0:\n",
    "                    edge_index[0, num_edges] = i\n",
    "                    edge_index[1, num_edges] = j\n",
    "                    edge_label[num_edges] = self.W[i, j]\n",
    "                    num_edges += 1\n",
    "\n",
    "        # resize edge list from number_nodes^2\n",
    "        edge_index = edge_index.resize_((2, num_edges))\n",
    "        edge_label = edge_label.resize_(num_edges, 1)\n",
    "        sequences = self._speed2vec(\n",
    "            edge_index,\n",
    "            edge_label,\n",
    "            num_nodes,\n",
    "            self.config[\"N_DAYS\"],\n",
    "            self.config[\"N_SLOT\"],\n",
    "            data_,\n",
    "            self.config[\"F\"],\n",
    "            self.config[\"H\"],\n",
    "        )\n",
    "        data_, slices = self.collate(sequences)\n",
    "\n",
    "        torch.save(\n",
    "            (data_, slices, num_nodes, mean, std),\n",
    "            self.processed_paths[0],\n",
    "        )\n",
    "\n",
    "    def _distance_to_weight(\n",
    "        self,\n",
    "        W: torch.tensor,\n",
    "        sigma2: float = 0.1,\n",
    "        epsilon: float = 0.5,\n",
    "        gat_version: bool = False,\n",
    "    ):\n",
    "        num_nodes = W.shape[0]\n",
    "        BASE_KM = 10_000.0\n",
    "        W = W / BASE_KM\n",
    "        W2 = W * W\n",
    "        W_mask = torch.ones([num_nodes, num_nodes]) - torch.eye(num_nodes)\n",
    "        W = (\n",
    "            torch.exp(-W2 / sigma2)\n",
    "            * (torch.exp(-W2 / sigma2) >= epsilon)\n",
    "            * W_mask\n",
    "        )\n",
    "\n",
    "        if gat_version:\n",
    "            W[W > 0] = 1\n",
    "            W += torch.eye(num_nodes)\n",
    "\n",
    "        return W\n",
    "\n",
    "    def _speed2vec(\n",
    "        self,\n",
    "        edge_index: torch.tensor,\n",
    "        edge_label: torch.tensor,\n",
    "        num_nodes: int,\n",
    "        n_days: int,\n",
    "        n_slot: int,\n",
    "        data_: torch.tensor,\n",
    "        F: int,\n",
    "        H: int,\n",
    "    ):\n",
    "        window_length = F + H\n",
    "        sequences = []\n",
    "        for i in range(n_days):\n",
    "            for j in range(n_slot):\n",
    "                G = data.Data()\n",
    "                G.__num_nodes__ = num_nodes\n",
    "                G.edge_index = edge_index\n",
    "                G.edge_label = edge_label\n",
    "\n",
    "                start = i * F + j\n",
    "                end = start + window_length\n",
    "                # transpose\n",
    "                full_windows = data_[start:end:].T\n",
    "                G.x = full_windows[:, 0:F]\n",
    "                G.y = full_windows[:, F::]\n",
    "                sequences.append(G)\n",
    "\n",
    "        return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TrafficDataset(config=config, root=\"../data/processed/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2688576, 12])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset._data.x.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
