{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Experiments\\BookRecommendationSystem\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Experiments\\BookRecommendationSystem\\notebooks\\Test.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Experiments/BookRecommendationSystem/notebooks/Test.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m encoding \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mencode_plus(\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Experiments/BookRecommendationSystem/notebooks/Test.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     sample,  \u001b[39m# Sentence to split into tokens\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Experiments/BookRecommendationSystem/notebooks/Test.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     add_special_tokens\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,  \u001b[39m# Add special token '[CLS]' and '[SEP]'\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Experiments/BookRecommendationSystem/notebooks/Test.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     max_length\u001b[39m=\u001b[39m\u001b[39m34\u001b[39m,  \u001b[39m# Pad & truncate all sentences.\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Experiments/BookRecommendationSystem/notebooks/Test.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     pad_to_max_length\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Experiments/BookRecommendationSystem/notebooks/Test.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     return_attention_mask\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,  \u001b[39m# Construct attention masks.\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Experiments/BookRecommendationSystem/notebooks/Test.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m,  \u001b[39m# Return pytorch tensors.\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Experiments/BookRecommendationSystem/notebooks/Test.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sample' is not defined"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer.encode_plus(\n",
    "    sample,  # Sentence to split into tokens\n",
    "    add_special_tokens=False,  # Add special token '[CLS]' and '[SEP]'\n",
    "    max_length=34,  # Pad & truncate all sentences.\n",
    "    pad_to_max_length=True,\n",
    "    return_attention_mask=True,  # Construct attention masks.\n",
    "    return_tensors=\"pt\",  # Return pytorch tensors.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 3640,  2019,  4955,  2000,  4556, 17218,  6885,  1996,  8280,  7832,\n",
       "          2306,  2037,  3439,  6123,  1010,  6594,  1997,  7611,  3350,  2004,\n",
       "          2490,  2005, 19336,  2824,  1010,  1998,  2129,  2122,  6991,  2031,\n",
       "          2042,  6791,  1999,  3906]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(range(1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratio = (1 - 0.8) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09999999999999998"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Experiments\\BookRecommendationSystem\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric import nn\n",
    "from torch_geometric import transforms as T\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "class BookReview:\n",
    "    \"\"\"Book Review dataset\n",
    "    Attributes:\n",
    "        + user_id: user's id (0 -> 67698)\n",
    "        + age: user'age\n",
    "        + city: user's city location\n",
    "        + state: user's state location\n",
    "        + country: user's country location\n",
    "        + isbn: book identify (67698 -> 138700)\n",
    "        + book_title: book's title\n",
    "        + book_author: book's author\n",
    "        + year_of_publication: books's publication year\n",
    "        + rating: the score user rate for the book\n",
    "        + Summary_{1,24}: the description of book embedded by BERT\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path: str) -> None:\n",
    "        self._path = path\n",
    "\n",
    "    def _load_dataset(self) -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "        summary_attr = [f\"Summary_{i}\" for i in range(1, 35)]\n",
    "        user_attributes = [\"user_id\", \"age\", \"city\", \"state\", \"country\"]\n",
    "        book_attributes = [\n",
    "            \"isbn\",\n",
    "            \"book_title\",\n",
    "            \"book_author\",\n",
    "            \"year_of_publication\",\n",
    "        ] + summary_attr\n",
    "\n",
    "        df = pd.read_csv(self._path)\n",
    "        users_df = df[user_attributes].reset_index(drop=True)\n",
    "        books_df = df[book_attributes].reset_index(drop=True)\n",
    "        rating_df = df[[\"user_id\", \"isbn\", \"rating\"]].reset_index(drop=True)\n",
    "\n",
    "        return users_df, books_df, rating_df\n",
    "\n",
    "    def __call__(self) -> HeteroData:\n",
    "        data = HeteroData()\n",
    "        users_df, books_df, rating_df = self._load_dataset()\n",
    "        y = torch.from_numpy(rating_df[\"rating\"].to_numpy())\n",
    "        edge_index = torch.from_numpy(\n",
    "            rating_df[[\"user_id\", \"isbn\"]].values.transpose()\n",
    "        )\n",
    "\n",
    "        data.name = \"Book rating\"\n",
    "        data[\"users\"].node_id = torch.from_numpy(\n",
    "            users_df[\"user_id\"].values\n",
    "        ).to(dtype=torch.int64)\n",
    "        data[\"books\"].node_id = torch.from_numpy(books_df[\"isbn\"].values).to(\n",
    "            dtype=torch.int64\n",
    "        )\n",
    "        data.number_of_users = len(users_df[\"user_id\"].unique())\n",
    "        data.number_of_books = len(books_df[\"isbn\"].unique())\n",
    "        books_df.drop([\"isbn\"], inplace=True, axis=1)\n",
    "        users_df.drop([\"user_id\"], inplace=True, axis=1)\n",
    "        data.number_of_nodes = data.number_of_users + data.number_of_books\n",
    "        data.number_of_user_node_features = len(users_df.columns)\n",
    "        data.number_of_book_node_features = len(books_df.columns)\n",
    "\n",
    "        feat_users_scaler = MinMaxScaler().fit_transform(users_df.to_numpy())\n",
    "        feat_books_scaler = MinMaxScaler().fit_transform(books_df.to_numpy())\n",
    "        data[\"users\"].x = torch.from_numpy(feat_users_scaler)\n",
    "        data[\"books\"].x = torch.from_numpy(feat_books_scaler)\n",
    "        data[\"users\", \"rating\", \"books\"].edge_index = edge_index\n",
    "        data[\"users\", \"books\"].edge_label = y\n",
    "        return data\n",
    "\n",
    "\n",
    "class HyperParameters:\n",
    "    BATCH_SIZE = 256\n",
    "    EPOCHS = 100\n",
    "    LEARNING_RATE = 0.005\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    book_review_dataset = BookReview(\n",
    "        path=\"../data/processed/BookReviewProcessedData_S.csv\"\n",
    "    )\n",
    "    dataset = book_review_dataset()\n",
    "    dataset = T.ToUndirected()(dataset)\n",
    "\n",
    "    transform = T.RandomLinkSplit(\n",
    "        num_val=0.1,\n",
    "        num_test=0.1,\n",
    "        disjoint_train_ratio=0.3,\n",
    "        neg_sampling_ratio=1.0,\n",
    "        add_negative_train_samples=True,\n",
    "        edge_types=(\"users\", \"rating\", \"books\"),\n",
    "        rev_edge_types=(\"books\", \"rev_rating\", \"users\"),\n",
    "        split_labels=True,\n",
    "    )\n",
    "\n",
    "    train, val, test = transform(dataset)\n",
    "    edge_label_index = train[\"users\", \"rating\", \"books\"].pos_edge_label_index\n",
    "    edge_label = train[\"users\", \"rating\", \"books\"].pos_edge_label\n",
    "\n",
    "    train_loader = LinkNeighborLoader(\n",
    "        data=train,\n",
    "        num_neighbors=[20, 10],\n",
    "        neg_sampling_ratio=2.0,\n",
    "        edge_label_index=((\"users\", \"rating\", \"books\"), edge_label_index),\n",
    "        edge_label=edge_label,\n",
    "        batch_size=HyperParameters.BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    \n",
    "    print(train_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
